{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal discovery with `TIGRAMITE`\n",
    "\n",
    "TIGRAMITE is a time series analysis python module. It allows to reconstruct graphical models (conditional independence graphs) from discrete or continuously-valued time series based on a causal discovery algorithm and create high-quality plots of the results.\n",
    "This tutorial explains the main features and gives walk-through examples. It covers:\n",
    "\n",
    "1. Basic usage\n",
    "2. Plotting\n",
    "3. Nonlinear conditional independence tests\n",
    "4. Symbolic time series\n",
    "5. Causal assumptions\n",
    "6. Missing values and masking\n",
    "7. Parallization\n",
    "8. PCMCI vs Granger causality\n",
    "9. Causal effects and mediation\n",
    "10. Optimal predictor selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline     \n",
    "## use `%matplotlib notebook` for interactive figures\n",
    "# plt.style.use('ggplot')\n",
    "import sklearn\n",
    "\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, GPDC, CMIknn, CMIsymb\n",
    "from tigramite.models import LinearMediation, Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider time series coming from a data generating process\n",
    "\n",
    "\\begin{align*}\n",
    "X^0_t &= 0.7 X^0_{t-1} - 0.8 X^1_{t-1} + \\eta^0_t\\\\\n",
    "X^1_t &= 0.8 X^1_{t-1} + 0.8 X^3_{t-1} + \\eta^1_t\\\\\n",
    "X^2_t &= 0.5 X^2_{t-1} + 0.5 X^1_{t-2} + 0.6 X^3_{t-3} + \\eta^2_t\\\\\n",
    "X^3_t &= 0.7 X^3_{t-1} + \\eta^3_t\\\\\n",
    "\\end{align*}\n",
    "\n",
    "where $\\eta$ are independent zero-mean unit variance random variables. Our goal is to reconstruct the drivers of each variable. In Tigramite such a process can be generated with the function ``pp.var_process``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(42)     # Fix random seed\n",
    "links_coeffs = {0: [((0, -1), 0.7), ((1, -1), -0.8)],\n",
    "                1: [((1, -1), 0.8), ((3, -1), 0.8)],\n",
    "                2: [((2, -1), 0.5), ((1, -2), 0.5), ((3, -3), 0.6)],\n",
    "                3: [((3, -1), 0.4)],\n",
    "                }\n",
    "T = 1000     # time series length\n",
    "data, true_parents_neighbors = pp.var_process(links_coeffs, T=T)\n",
    "T, N = data.shape\n",
    "\n",
    "# Initialize dataframe object\n",
    "dataframe = pp.DataFrame(data)\n",
    "\n",
    "# Specify time axis and variable names\n",
    "datatime = numpy.arange(len(data))\n",
    "var_names = [r'$X^0$', r'$X^1$', r'$X^2$', r'$X^3$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we plot the time series. This can be done with the function ``tp.plot_timeseries``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp.plot_timeseries(data, datatime, var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's stationary and doesn't contain missing values (covered below). Next, we choose a conditional independence test, here we start with ``ParCorr`` implementing linear partial correlation. With ``significance='analytic'`` the null distribution is assumed to be Student's $t$. Then we initialize the ``PCMCI`` method with  ``dataframe``, ``cond_ind_test``, and (optionally) ``var_names``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parcorr = ParCorr(significance='analytic')\n",
    "pcmci = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the causal algorithm, it's a good idea to plot the lagged unconditional dependencies, e.g., the lagged correlations. This can help to identify which maximal time lag ``tau_max`` to choose in the causal algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = pcmci.get_lagged_dependencies(tau_max=20)\n",
    "lag_func_matrix = tp.plot_lagfuncs(val_matrix=correlations, var_names=var_names, \n",
    "                                    x_base=5, y_base=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dependencies decay beyond a maximum lag of around 8, we choose ``tau_max=8`` for the causal algorithm. The other main parameter is ``pc_alpha`` which sets the significance level in the condition-selection step. Here we let PCMCI choose the optimal value by setting it to ``pc_alpha=None``. Then PCMCI will optimize this parameter in the ParCorr case by the Akaike Information criterion among a reasonable default list of values (``pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pcmci.run_pcmci(tau_max=8, pc_alpha=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output, PCMCI selected different ``pc_alpha`` for each variable. The result of ``run_pcmci`` is a dictionary containing the matrix of p-values, the matrix of test statistic values (here MCI partial correlations), and optionally its confidence bounds (can be specified upon initializing ``ParCorr``). ``p_matrix`` and ``val_matrix`` are of shape ``(N, N, tau_max+1)`` with entry ``(i, j, \\tau)`` denoting the test for the link $X^i_{t-\\tau} \\to X^j_t$. Per default, the MCI values for $\\tau=0$ are not evaluated (can be changed with ``tau_min`` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p-values\")\n",
    "print results['p_matrix'].round(3)\n",
    "print(\"MCI partial correlations\")\n",
    "print results['val_matrix'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to control for the $N^2 \\tau_\\max$ tests conducted here, we can further correct the p-values, e.g., by False Discovery Rate (FDR) control yielding the ``q_matrix``. At a chosen significance level the detected parents of each variable can then be printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], fdr_method='fdr_bh')\n",
    "pcmci._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        q_matrix = q_matrix,\n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tigramite currently offers three plotting options: The lag function matrix (as shown above), the time series graph, and the process graph which aggregates the information in the time series graph. Both take as arguments the boolean ``link_matrix`` which denotes significant links by ``1``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link_matrix = pcmci._return_significant_parents(pq_matrix=q_matrix,\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process graph, the node color denotes the auto-MCI value and the link colors the cross-MCI value. If links occur at multiple lags between two variables, the link color denotes the strongest one and the label lists all significant lags in order of their strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp.plot_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='cross-MCI',\n",
    "    node_colorbar_label='auto-MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series graph\n",
    "tp.plot_time_series_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the process graph is nicer to look at, the time series graph better represents the spatio-temporal dependency structure from which causal pathways can be read off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nonlinear conditional independence tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If nonlinear dependencies are present, it is advisable to use a nonparametric test. Consider the following model:\n",
    "\n",
    "\\begin{align*}\n",
    "    X^0_t &= 0.2 (X^1_{t-1})^2 + \\eta^0_t\\\\\n",
    "    X^1_t &= \\eta^1_t \\\\\n",
    "    X^2_t &= 0.3 (X^1_{t-2})^2 + \\eta^2_t\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "    data[t, 0] += 0.4*data[t-1, 1]**2\n",
    "    data[t, 2] += 0.3*data[t-2, 1]**2\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci_parcorr = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``ParCorr`` here fails in two ways: (1) It cannot detect the two nonlinear links, (2) it wrongly detects a link $X^0_{t-1} \\to X^2_t$ because it also cannot *condition out* a nonlinear dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPDC\n",
    "\n",
    "Tigramite covers nonlinear additive dependencies with a test based on *Gaussian process* regression and a *distance correlation* (``GPDC``) or *maximal correlation* (``GPACE``) on the residuals. Here we demonstrate GPDC since GPACE requires an R-package. For GPDC no analytical null distribution is available. One can either use a computationally expensive shuffle test throughout or the null distribution can be pre-computed for different anticipated sample sizes with ``generate_and_save_nulldists`` and stored to disk (could be run overnight:). Then ``significance='analytic'`` loads this file. If no file is given, the distribution is generated and stored in cache. GP regression is performed with ``sklearn`` default parameters, except for the *kernel* which here defaults to the radial basis function + a white kernel (both hyperparameters are internally optimized) and the assumed noise level ``alpha`` which is set to zero since we added a white kernel. These and other parameters can be set via the ``gp_params`` dictionary. See the documentation in ``sklearn`` for further discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpdc = GPDC(significance='analytic', gp_params=None)\n",
    "# gpdc.generate_and_save_nulldists(sample_sizes=range(495, 501),\n",
    "#     null_dist_filename='dc_nulldists.npz')\n",
    "gpdc.null_dist_filename ='dc_nulldists.npz'\n",
    "pcmci_gpdc = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=gpdc,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to ParCorr, the nonlinear links are correctly detected with GPDC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pcmci_gpdc.run_pcmci(tau_max=2, pc_alpha=0.1)\n",
    "pcmci_gpdc._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a short excursion, we can see how GPDC works looking at the scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array, dymmy, dummy = gpdc._get_array(X=[(0, -1)], Y=[(2, 0)], Z=[(1, -2)], tau_max=2)\n",
    "x, meanx = gpdc._get_single_residuals(array, target_var=0, return_means=True)\n",
    "y, meany = gpdc._get_single_residuals(array, target_var=1, return_means=True)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8,3))\n",
    "axes[0].scatter(array[2], array[0], color='grey')\n",
    "axes[0].scatter(array[2], meanx, color='black')\n",
    "axes[0].set_title(\"GP of %s on %s\" % (var_names[0], var_names[1]) )\n",
    "axes[0].set_xlabel(var_names[1]); axes[0].set_ylabel(var_names[0])\n",
    "axes[1].scatter(array[2], array[1], color='grey')\n",
    "axes[1].scatter(array[2], meany, color='black')\n",
    "axes[1].set_title(\"GP of %s on %s\" % (var_names[2], var_names[1]) )\n",
    "axes[1].set_xlabel(var_names[1]); axes[1].set_ylabel(var_names[2])\n",
    "axes[2].scatter(x, y, color='red')\n",
    "axes[2].set_title(\"DC of residuals:\" \"\\n val=%.3f / p-val=%.3f\" % (gpdc.run_test(\n",
    "            X=[(0, -1)], Y=[(2, 0)], Z=[(1, -2)], tau_max=2)) )\n",
    "axes[2].set_xlabel(\"resid. \"+var_names[0]); axes[2].set_ylabel(\"resid. \"+var_names[2])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some even more nonlinear dependencies in a model with multiplicative noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)\n",
    "data = numpy.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "    data[t, 0] *= 0.2*data[t-1, 1]\n",
    "    data[t, 2] *= 0.3*data[t-2, 1]\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since multiplicative noise violates the assumption of additive dependencies underlying GPDC, the spurious link  $X^0_{t-1} \\to X^2_t$ is wrongly detected because it cannot be *conditioned out*. In contrast to ParCorr, however, the two true links *are* detected because DC detects any kind of dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci_gpdc = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=gpdc,\n",
    "    var_names=var_names)\n",
    "results = pcmci_gpdc.run_pcmci(tau_max=2, pc_alpha=0.1)\n",
    "pcmci_gpdc._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMIknn\n",
    "\n",
    "The most general conditional independence test implemented in Tigramite is CMIknn based on conditional mutual information estimated with a k-nearest neighbor estimator. CMIknn involves no assumptions about the dependencies. The parameter ``knn`` determines the size of hypercubes, ie., the (data-adaptive) local length-scale. Now we cannot even pre-compute the null distribution because CMIknn is not residual-based like GPDC and the nulldistribution depends on many more factors. We, therefore, use ``significance='shuffle_test'`` to generate it in each individual test. The following cell may take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cmi_knn = CMIknn(significance='shuffle_test', knn=50)\n",
    "# pcmci_cmi_knn = PCMCI(\n",
    "#     dataframe=dataframe, \n",
    "#     cond_ind_test=cmi_knn,\n",
    "#     var_names=var_names,\n",
    "#     verbosity=2)\n",
    "# results = pcmci_cmi_knn.run_pcmci(tau_max=2, pc_alpha=0.05)\n",
    "# pcmci_cmi_knn._print_significant_links(\n",
    "#         p_matrix = results['p_matrix'], \n",
    "#         val_matrix = results['val_matrix'],\n",
    "#         alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Significant parents at alpha = 0.01:\n",
    "\n",
    "#     Variable $X^0$ has 1 parent(s):\n",
    "#         ($X^1$ -1): pval = 0.00000 | val = 0.106\n",
    "\n",
    "#     Variable $X^1$ has 0 parent(s):\n",
    "\n",
    "#     Variable $X^2$ has 1 parent(s):\n",
    "#         ($X^1$ -2): pval = 0.00000 | val = 0.056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here CMIknn correctly detects the true links and also unveils the spurious link. While CMIknn may now seem as the best independence test choice, we have to note that the generality comes at the cost of much lower power for the case that the dependencies actually follow some parametric form. Then ParCorr or GPDC are much more powerful measures. Of course, ParCorr also detects linear links better than GPDC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Symbolic time series\n",
    "\n",
    "Symbolic (or discrete) data may arise naturally or continuously-valued time series can be converted to symbolic data. To accommodate such time series, Tigramite includes the ``CMIsymb`` conditional independence test based on conditional mutual information estimated directly from the histogram of discrete values. Usually a (quantile-)binning  applied to continuous data in order to use a discrete CMI estimator is not recommended (rather use ``CMIknn``), but here we do it anyway to get some symbolic data. We again consider the nonlinear time series example and convert to a symbolic series with 4 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(2000, 3)\n",
    "for t in range(1, 2000):\n",
    "    data[t, 0] += 0.4*data[t-1, 1]**2\n",
    "    data[t, 2] += 0.3*data[t-2, 1]**2\n",
    "data = pp.quantile_bin_array(data, bins=4)\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, figsize=(10,4), var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMIsymb is initialized with ``n_symbs=None`` implying that the number of symbols is determined as ``n_symbs=data.max()+1``. Again, we have to use a shuffle test. Symbolic CMI works not very well here, only for 2000 samples was the correct graph reliably detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cmi_symb = CMIsymb(significance='shuffle_test', n_symbs=None)\n",
    "# pcmci_cmi_symb = PCMCI(\n",
    "#     dataframe=dataframe, \n",
    "#     cond_ind_test=cmi_symb,\n",
    "#     var_names=var_names)\n",
    "# results = pcmci_cmi_symb.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "# pcmci_cmi_symb._print_significant_links(\n",
    "#         p_matrix = results['p_matrix'], \n",
    "#         val_matrix = results['val_matrix'],\n",
    "#         alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Significant parents at alpha = 0.01:\n",
    "\n",
    "#     Variable $X^0$ has 1 parent(s):\n",
    "#         ($X^1$ -1): pval = 0.00000 | val = 0.040\n",
    "\n",
    "#     Variable $X^1$ has 0 parent(s):\n",
    "\n",
    "#     Variable $X^2$ has 1 parent(s):\n",
    "#         ($X^1$ -2): pval = 0.00000 | val = 0.036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Causal assumptions\n",
    "\n",
    "Having introduced the basic functionality, we now turn to a discussion of the assumptions underlying a causal interpretation:\n",
    "\n",
    "  - **Faithfulness / Stableness:** *Independencies in data arise not from incredible coincidence, but rather from causal structure.*\n",
    "  \n",
    "  - **Causal Sufficiency:** *Measured variables include all of the common causes.*\n",
    "  \n",
    "  - **Causal Markov Condition:** *All the relevant probabilistic information that can be obtained from the system is contained in its direct causes.*\n",
    "  \n",
    "  - **No contemporaneous effects:** *Contemporaneous dependencies arise only from latent common drivers*\n",
    "  \n",
    "  - **Stationarity**\n",
    "  \n",
    "  - **Parametric assumptions of independence tests** (these where already discussed above)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness\n",
    "\n",
    "Faithfulness, as stated above, is an expression of the assumption that the independencies we measure come from the causal structure, i.e., the time series graph, and cannot occur due to some fine tuning of the parameters. Another unfaithful case are processes containing *purely* deterministic dependencies, i.e., $Y=f(X)$, without any noise. We illustrate these cases in the following.\n",
    "\n",
    "#### Fine tuning\n",
    "\n",
    "Suppose in our model we have two ways in which $X^0$ causes $X^2$, a direct one, and an indirect effect $X^0\\to X^1 \\to X^2$ as realized in the following model:\n",
    "\n",
    "\\begin{align*}\n",
    "    X^0_t &= \\eta^0_t\\\\\n",
    "    X^1_t &= 0.6 X^0_{t-1} + \\eta^1_t\\\\\n",
    "    X^2_t &= 0.6 X^1_{t-1} - 0.36 X^0_{t-2} + \\eta^2_t\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "#     data[t, 0] += 0.6*data[t-1, 1]\n",
    "    data[t, 1] += 0.6*data[t-1, 0]\n",
    "    data[t, 2] += 0.6*data[t-1, 1] - 0.36*data[t-2, 0]\n",
    "dataframe = pp.DataFrame(data)\n",
    "# tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since here $X^2_t = 0.6 X^1_{t-1} - 0.36 X^0_{t-2} + \\eta^2_t = 0.6 (0.6 X^0_{t-2} + \\eta^1_{t-1}) - 0.36 X^0_{t-2} + \\eta^2_t = 0.36 X^0_{t-2} - 0.36 X^0_{t-2} + ...$, there is no unconditional dependency $X^0_{t-2} \\to X^2_t$ and the link is not detected in the condition-selection step: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr()\n",
    "pcmci_parcorr = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "all_parents = pcmci_parcorr.run_pc_stable(tau_max=2, pc_alpha=0.2)\n",
    "print (\"Conditions:\")\n",
    "pcmci_parcorr._print_parents(all_parents, pcmci_parcorr.test_statistic_values, pcmci_parcorr.p_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since the other parent of $X^2$, namely $X^1_{t-1}$ *is* detected, the MCI step conditions on $X^1_{t-1}$ and can reveal the true underlying graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that this is not always the case and parameter-fine tuning, even though a pathological case, can present a problem especially for smaller sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterministic dependencies\n",
    "\n",
    "Another violation of faithfulness can happen due to *purely* deterministic dependencies as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "    data[t, 0] = 0.4*data[t-1, 1]\n",
    "    data[t, 2] += 0.3*data[t-2, 1] + 0.7*data[t-1, 0]\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr()\n",
    "pcmci_parcorr = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the partial correlation $X^1_{t-1} \\to X^0_t$ is exactly 1. Since these now represent the same variable, the true link $X^0_{t-1} \\to X^0_t$ cannot be detected anymore since we condition on $X^0_{t-2}$. Deterministic copies of other variables should be excluded from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal sufficiency\n",
    "\n",
    "Causal sufficiency demands that the set of variables contains all common causes of any two variables. This is assumption is mostly violated when analyzing open complex systems outside a confined experimental setting. Any link estimated from a causal discovery algorithm could become non-significant if more variables are included in the analysis. \n",
    "Observational causal inference should generally be seen more as one step towards a physical process understanding. It can greatly help in an explorative model building analysis to get an idea of potential drivers. In particular, the absence of a link allows for a more robust conclusion: If there is no evidence for a statistical dependency, then a physical mechanism is less likely (assuming that the other assumptions hold).\n",
    "\n",
    "#### Unobserved driver / latent variable\n",
    "\n",
    "For the common driver process, consider that the common driver was not measured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "    data[t, 0] += 0.6*data[t-1, 1]\n",
    "    data[t, 2] += 0.7*data[t-2, 1]\n",
    "# tp.plot_timeseries(data, var_names=var_names)\n",
    "obsdata = data[:,[0,2]]\n",
    "# tp.plot_timeseries(obsdata, var_names=[var_names[0], var_names[2]])\n",
    "dataframe = pp.DataFrame(obsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it is impossible here to detect that the link $X^0\\to X^2$ is spurious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr()\n",
    "pcmci_parcorr = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=[var_names[0], var_names[2]],\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solar forcing\n",
    "\n",
    "In a geoscientific context, the solar forcing typically is a strong common driver of many processes. To remove this trivial effect, time series are typically anomalized, that is, the average seasonal cycle is subtracted. But one could also include the solar forcing explicitely as shown here via a sine wave for an artificial example. We've also made the time series more realistic by adding an auto-dependency on their past values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(1000, 4)\n",
    "# Simple sun\n",
    "data[:,3] = numpy.sin(numpy.arange(1000)*20/numpy.pi)\n",
    "var_names[3] = 'Sun'\n",
    "c = 0.8\n",
    "for t in range(1, 1000):\n",
    "    data[t, 0] += 0.4*data[t-1, 0] + 0.4*data[t-1, 1] + c*data[t-1,3]\n",
    "    data[t, 1] += 0.5*data[t-1, 1] + c*data[t-1,3]\n",
    "    data[t, 2] += 0.6*data[t-1, 2] + 0.3*data[t-2, 1] + c*data[t-1,3]\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not account for the common solar forcing, there will be many spurious links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr()\n",
    "dataframe_nosun = pp.DataFrame(data[:,[0,1,2]])\n",
    "pcmci_parcorr = PCMCI(\n",
    "    selected_variables = [0,1,2],\n",
    "    dataframe=dataframe_nosun, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we explicitely include the solar forcing variable (which we assume is known in this case), we can identify the correct causal graph. Since we are not interested in the drivers of the solar forcing variable, we don't attempt to reconstruct its parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr()\n",
    "pcmci_parcorr = PCMCI(\n",
    "    selected_variables = [0,1,2],\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time sub-sampling\n",
    "\n",
    "Sometimes a time series might be sub-sampled, that is the measurements are less frequent than the true underlying time-dependency. Consider the following process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(1000, 3)\n",
    "for t in range(1, 1000):\n",
    "    data[t, 0] += 0.*data[t-1, 0] + 0.6*data[t-1,2]\n",
    "    data[t, 1] += 0.*data[t-1, 1] + 0.6*data[t-1,0]\n",
    "    data[t, 2] += 0.*data[t-1, 2] + 0.6*data[t-1,1]\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the original time sampling we obtain the correct causal graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci_parcorr = PCMCI(dataframe=dataframe, cond_ind_test=ParCorr(), var_names=var_names)\n",
    "results = pcmci_parcorr.run_pcmci(tau_min=0,tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_matrix = pcmci_parcorr._return_significant_parents(pq_matrix=results['p_matrix'],\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "# Plot time series graph\n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(6, 3),\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sub-sample the data, very counter-intuitive links can appear. The true causal loop gets detected in the wrong direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = data[::2]\n",
    "pcmci_parcorr = PCMCI(dataframe=pp.DataFrame(sampled_data), cond_ind_test=ParCorr(), \n",
    "                      var_names=var_names, verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_min=0, tau_max=2, pc_alpha=0.2)\n",
    "link_matrix = pcmci_parcorr._return_significant_parents(pq_matrix=results['p_matrix'],\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "# Plot time series graph\n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(6, 3),\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If causal lags are smaller than the time sampling, such problems occur. Causal inference for sub-sampled data is still an active area of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Markov condition\n",
    "\n",
    "The Markov condition can be rephrased as assuming that the noises driving each variable are independent of each other *and* independent in time (*iid*). This is violated in the following example where each variable is driven by *1/f* noise which refers to the scaling of the power spectrum. *1/f* noise can be generated by averaging AR(1) processes (http://www.scholarpedia.org/article/1/f_noise) which means that the noise is not independent in time anymore (even though the noise terms of each individual variable are still independent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "T = 10000\n",
    "# Generate 1/f noise by averaging AR1-process with wide range of coeffs \n",
    "# (http://www.scholarpedia.org/article/1/f_noise)\n",
    "def one_over_f_noise(T, n_ar=20):\n",
    "    whitenoise = numpy.random.randn(T, n_ar)\n",
    "    ar_coeffs = numpy.linspace(0.1, 0.9, n_ar)\n",
    "    for t in range(T):\n",
    "        whitenoise[t] += ar_coeffs*whitenoise[t-1]       \n",
    "    return whitenoise.sum(axis=1)\n",
    "\n",
    "data = numpy.random.randn(T, 3)\n",
    "data[:,0] += one_over_f_noise(T)\n",
    "data[:,1] += one_over_f_noise(T)\n",
    "data[:,2] += one_over_f_noise(T)\n",
    "\n",
    "for t in range(1, T):\n",
    "    data[t, 0] +=  0.4*data[t-1, 1] \n",
    "    data[t, 2] +=  0.3*data[t-2, 1] \n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)\n",
    "plt.psd(data[:,0],return_line=True)[2]\n",
    "plt.psd(data[:,1],return_line=True)[2]\n",
    "plt.psd(data[:,2],return_line=True)[2]\n",
    "plt.gca().set_xscale(\"log\", nonposx='clip')\n",
    "plt.gca().set_yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here PCMCI will detect many spurious links, especially auto-dependencies, since the process has *long memory* and the present state is *not* independent of the further past given some set of parents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr()\n",
    "pcmci_parcorr = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=5, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time aggregation\n",
    "\n",
    "An important choice is how to aggregate measured time series. For example, climate time series might have been measured daily, but one might be interested in a less noisy time-scale and analyze monthly aggregates. Consider the following process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(1000, 3)\n",
    "for t in range(1, 1000):\n",
    "    data[t, 0] += 0.7*data[t-1, 0] \n",
    "    data[t, 1] += 0.6*data[t-1, 1] + 0.6*data[t-1,0]\n",
    "    data[t, 2] += 0.5*data[t-1, 2] + 0.6*data[t-1,1]\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the original time aggregation we obtain the correct causal graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci_parcorr = PCMCI(dataframe=dataframe, cond_ind_test=ParCorr(), var_names=var_names)\n",
    "results = pcmci_parcorr.run_pcmci(tau_min=0,tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_matrix = pcmci_parcorr._return_significant_parents(pq_matrix=results['p_matrix'],\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "# Plot time series graph\n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(6, 3),\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we aggregate the data, we also detect a contemporaneous dependency for which no causal direction can be assessed in this framework and we obtain also several lagged spurious links. Essentially, we now have direct causal effects that appear contemporaneous on the aggregated time scale. Also causal inference for time-aggregated data is still an active area of research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_data = pp.time_bin_with_mask(data, time_bin_length=4)\n",
    "pcmci_parcorr = PCMCI(dataframe=pp.DataFrame(aggregated_data[0]), cond_ind_test=ParCorr(), \n",
    "                      var_names=var_names, verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_min=0, tau_max=2, pc_alpha=0.2)\n",
    "# pcmci_parcorr._print_significant_links(\n",
    "#         p_matrix = results['p_matrix'], \n",
    "#         val_matrix = results['val_matrix'],\n",
    "#         alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_matrix = pcmci_parcorr._return_significant_parents(pq_matrix=results['p_matrix'],\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "# Plot time series graph\n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(6, 3),\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values and masking\n",
    "\n",
    "### Missing values\n",
    "\n",
    "Tigramite consistently handles missing values. For example, missing values denoted as ``999.`` in the data can be flagged with ``ParCorr.set_dataframe(data, missing_flag=999.)``. Then all time slices of samples where missing values occur in any variable are dismissed while consistently handling time lags. To avoid biases also subsequent samples for all lags up to ``2*tau_max`` are dismissed, see section on masking in Supplement of description paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "data = numpy.random.randn(100, 3)\n",
    "for t in range(1, 100):\n",
    "    data[t, 0] += 0.7*data[t-1, 0] \n",
    "    data[t, 1] += 0.6*data[t-1, 1] + 0.6*data[t-1,0]\n",
    "    data[t, 2] += 0.5*data[t-1, 2] + 0.6*data[t-1,1]\n",
    "# Randomly mark 30% of values as missing values in variable 2\n",
    "data[numpy.random.permutation(100)[:10], 2] = 999.\n",
    "tp.plot_timeseries(data, missing_flag=999., var_names=var_names)\n",
    "dataframe = pp.DataFrame(data, missing_flag=999.)\n",
    "pcmci_parcorr = PCMCI(dataframe=dataframe, cond_ind_test=ParCorr(verbosity=3), \n",
    "                      var_names=var_names, verbosity=4)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr._print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "Different from missing values, masking can be used to include or exclude samples depending on the situation: For example, in climate research we frequently are interested to detect the drivers of a target variable *only in winter months*. Thus, in all independent tests $X \\perp Y | Z$ carried out during a PCMCI analysis, we require samples of $Y$ to be from the winter only, while lagged samples of $X$ or $Z$ can also come from the previous summer. This can be achieved with ``mask_type='y'`` in initializing ``ParCorr``' and marking all winter month data in $Y$ in ``mask``. If we want *all* samples, also in $X$ and $Z$ to be restricted to winter months, we need to mark them in ``mask`` as well and set  ``mask_type='yxz'``. Correspondingly, also  ``mask_type='z'`` or any combination is possible. See the section on masking in the Supplement of the description paper for more details.\n",
    "\n",
    "In the following example, we generate data with a different underlying causality for winter and summer months. In particular, assume a causal effect is of opposite sign in both seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking demo: We consider time series where the first half is generated by a different\n",
    "# causal process than the second half. \n",
    "numpy.random.seed(42)\n",
    "T = 1000\n",
    "data = numpy.random.randn(T, 2)\n",
    "data_mask = numpy.zeros(data.shape)\n",
    "for t in range(1, T):\n",
    "#     print t % 365\n",
    "    if (t % 365) < 3*30 or (t % 365) > 8*30: \n",
    "        # Winter half year\n",
    "        data[t, 0] +=  0.4*data[t-1, 0]\n",
    "        data[t, 1] +=  0.3*data[t-1, 1] + 0.9*data[t-1, 0]\n",
    "    else:\n",
    "        # Summer half year\n",
    "        data_mask[[t, t-1]] = True\n",
    "        data[t, 0] +=  0.4*data[t-1, 0]\n",
    "        data[t, 1] +=  0.3*data[t-1, 1] - 0.9*data[t-1, 0]\n",
    "\n",
    "T, N = data.shape\n",
    "# print data_mask[:100, 0]\n",
    "dataframe = pp.DataFrame(data, mask=data_mask)\n",
    "tp.plot_timeseries(data, figsize=(8,3),  var_names=var_names, use_mask=True, mask=data_mask, \n",
    "                             grey_masked_samples='data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup analysis\n",
    "def run_and_plot(cond_ind_test, fig_ax):\n",
    "    pcmci = PCMCI(dataframe=dataframe, cond_ind_test=cond_ind_test, var_names=var_names)\n",
    "    results = pcmci.run_pcmci(tau_max=2,pc_alpha=0.2, )\n",
    "    link_matrix = pcmci._return_significant_parents(pq_matrix=results['p_matrix'],\n",
    "            val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "    tp.plot_graph(fig_ax = fig_ax,  val_matrix=results['val_matrix'],\n",
    "                  link_matrix=link_matrix, var_names=var_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal graph of whole year yields no link because effects average out\n",
    "fig  = plt.figure(figsize=(3,2)); ax=fig.add_subplot(111)\n",
    "run_and_plot(ParCorr(use_mask=False), (fig, ax))\n",
    "\n",
    "# # Causal graph of winter half only gives positive link\n",
    "fig  = plt.figure(figsize=(3,2)); ax=fig.add_subplot(111)\n",
    "run_and_plot(ParCorr(use_mask=True, mask_type='y'), (fig, ax))\n",
    "\n",
    "# Causal graph of summer half only gives negative link\n",
    "fig  = plt.figure(figsize=(3,2)); ax=fig.add_subplot(111)\n",
    "dataframe.mask = (dataframe.mask == False)\n",
    "run_and_plot(ParCorr(use_mask=True, mask_type='y'),  (fig, ax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7. Parallization\n",
    "\n",
    "The repository also contains a script ``run_pcmci_parallel`` that parallelizes the tigramite PCMCI function. It requires ``mpi4py`` to be installed. The data and parameters can be set in the script itself and it can be run from a shell with:\n",
    "\n",
    "``$ mpirun -np 4 python run_pcmci_parallel.py``\n",
    "\n",
    "Here ``-np 4`` specifies the number of cores available. This script can be run on multiple processors on a single machine or also on a cluster computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 8. PCMCI vs One-step full conditioning aka Granger causality\n",
    "\n",
    "An alternative way to estimate the time series graph is to directly test links by their defining equation\n",
    "\n",
    "\\begin{align*}\n",
    "X^i_{t-\\tau} \\perp X^j_t ~|~ \\mathbf{X}^-_t\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{X}^-_t=(\\mathbf{X}_{t-1}, \\mathbf{X}_{t-2}, \\ldots)$ is the past of the whole process. This is the approach of a *lag-specific* version of Granger causality (GC) or Transfer entropy. This approach gives lower detection power for two reasons:\n",
    "\n",
    "1. Smaller *effect size* of GC compared to MCI\n",
    "2. Higher dimensionality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Smaller *effect size* of GC compared to MCI\n",
    "\n",
    "Consider the following system:\n",
    "\n",
    "\\begin{align*} \n",
    "Z_t &= a Z_{t-1} + c_{XZ} X_{t-1} + \\eta^Z_t  \\\\\n",
    "X_t &= a_{X} X_{t-1} + c_{WX} W_{t-1} + \\eta^X_t  \\\\\n",
    "Y_t &= a Y_{t-1} + c_{XY} X_{t-2} + c_{WY} W_{t-3} + \\eta^Y_t \\\\\n",
    "W_t &= a W_{t-1} + \\eta^W_t\n",
    "\\end{align*}\n",
    "\n",
    "with independent Gaussian white noise processes $\\eta^{\\cdot}_t$ with variances $\\sigma^2_{\\cdot}$. Considering the link $X_{t-2}\\to Y_t$, here it can be shown (see description paper) that the test statistic $I^{GC}(X_{t-2}\\to Y_t) \\leq I^{MCI}(X_{t-2}\\to Y_t)$ generally. In the paper this is proven for arbitrary models. Measuring a smaller effect size implies a lower power to detect this particular link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup analysis\n",
    "numpy.random.seed(42)     # Fix random seed\n",
    "links_coeffs = {0: [((0, -1), 0.9), ((1, -2), -0.25)],\n",
    "                1: [((1, -1), 0.95), ((3, -3), 0.3)],\n",
    "                2: [((2, -1), 0.85), ((1, -2), 0.3), ((3, -3), 0.3)],\n",
    "                3: [((3, -1), 0.9)],\n",
    "                }\n",
    "T = 100     # time series length\n",
    "N = len(links_coeffs.keys())\n",
    "tau_max = 5\n",
    "realizations = 100\n",
    "alpha_level = 0.05\n",
    "\n",
    "var_names = [r'$Z$', r'$X$', r'$Y$', r'$W$']\n",
    "# Define whole past\n",
    "whole_past = {}\n",
    "for j in range(N):\n",
    "    whole_past[j] = [(var, -lag)\n",
    "                         for var in range(N)\n",
    "                         for lag in range(1, tau_max + 1)\n",
    "                    ]\n",
    "def get_sig_links():\n",
    "    p_matrices = {'PCMCI':numpy.ones((realizations, N, N, tau_max+1)),\n",
    "                  'GC':numpy.ones((realizations, N, N, tau_max+1))}\n",
    "    val_matrices = {'PCMCI':numpy.zeros((realizations, N, N, tau_max+1)),\n",
    "                  'GC':numpy.zeros((realizations, N, N, tau_max+1))}  \n",
    "    for i in range(realizations):\n",
    "        data, true_parents_neighbors = pp.var_process(links_coeffs, T=T)\n",
    "        dataframe = pp.DataFrame(data)\n",
    "        \n",
    "        # PCMCI\n",
    "        pcmci = PCMCI(dataframe=dataframe, cond_ind_test=ParCorr())\n",
    "        results = pcmci.run_pcmci(tau_max=tau_max, pc_alpha=0.2)\n",
    "        p_matrices['PCMCI'][i] = results['p_matrix']\n",
    "        val_matrices['PCMCI'][i] = results['val_matrix']\n",
    "\n",
    "        # Condition on whole past\n",
    "        results = pcmci.run_mci(tau_max=tau_max,parents=whole_past)\n",
    "        p_matrices['GC'][i] = results['p_matrix']\n",
    "        val_matrices['GC'][i] = results['val_matrix']\n",
    "\n",
    "    # Get true positive rate (=power) and false positive rate \n",
    "    sig_links = {'PCMCI':(p_matrices['PCMCI'] <= alpha_level).mean(axis=0),\n",
    "                  'GC':(p_matrices['GC'] <= alpha_level).mean(axis=0),}\n",
    "    ave_val_matrices = {'PCMCI':val_matrices['PCMCI'].mean(axis=0),\n",
    "                  'GC':val_matrices['GC'].mean(axis=0),}\n",
    "    return sig_links, ave_val_matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_links, ave_val_matrices = get_sig_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimated how often a link was detected at the given ``alpha_level`` and plot this fraction as the width of the links while the average effect size for each link is given as the color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing detection power as width of links\n",
    "min_sig = 0.2\n",
    "vminmax = 0.5\n",
    "link_matrix = (sig_links['PCMCI'] > min_sig)\n",
    "tp.plot_graph(val_matrix=ave_val_matrices['PCMCI'],\n",
    "              link_matrix=link_matrix, var_names=var_names,\n",
    "              link_width=sig_links['PCMCI'],\n",
    "             arrow_linewidth=70.,\n",
    "              vmin_edges=-vminmax,\n",
    "              vmax_edges=vminmax,\n",
    "\n",
    ")\n",
    "link_matrix = (sig_links['GC'] > min_sig)\n",
    "tp.plot_graph(val_matrix=ave_val_matrices['GC'],\n",
    "              link_matrix=link_matrix, var_names=var_names,\n",
    "              link_width=sig_links['GC'], \n",
    "              link_colorbar_label='GC',\n",
    "              node_colorbar_label='auto-GC',\n",
    "             arrow_linewidth=70.,\n",
    "              vmin_edges=-vminmax,\n",
    "              vmax_edges=vminmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, the power of GC is lower purely due to GC's test statistic effect size being smaller. MCI has been constructed to estimate a certain notion of *causal strength* as discussed in the paper. MCI, thus, alleviates the effect of other dependencies on a particular link. In large-scale studies, this feature allows to rank links by their causal strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Higher dimensionality \n",
    "\n",
    "An obvious drawback of GC is that it always includes the whole past as a condition leading to very high estimation dimension which results in lower power. In the following we consider a model with only one true link and many irrelevant independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup analysis\n",
    "numpy.random.seed(42)     # Fix random seed\n",
    "links_coeffs = {0: [((0, -1), 0.9), ((1, -2), -0.25)],\n",
    "                1: [((1, -1), 0.95), ((3, -3), 0.3)],\n",
    "                2: [((2, -1), 0.85), ((1, -2), 0.3), ((3, -3), 0.3)],\n",
    "                3: [((3, -1), 0.9)],\n",
    "                }\n",
    "T = 80     # time series length\n",
    "tau_max = 5\n",
    "realizations = 100\n",
    "alpha_level = 0.05\n",
    "n_variables = 9\n",
    "\n",
    "# Add independent variables\n",
    "for d in range(4, n_variables):\n",
    "    links_coeffs[d] = [((d, -1), 0.2 + numpy.random.rand()*0.7)]\n",
    "    \n",
    "var_names = [r'$Z$', r'$X$', r'$Y$', r'$W$'] + range(4, n_variables)\n",
    "\n",
    "N = len(links_coeffs.keys())\n",
    "# Define whole past\n",
    "whole_past = {}\n",
    "for j in range(N):\n",
    "    whole_past[j] = [(var, -lag)\n",
    "                         for var in range(N)\n",
    "                         for lag in range(1, tau_max + 1)\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may take some minutes\n",
    "sig_links, ave_val_matrices = get_sig_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing detection power as width of links\n",
    "min_sig = 0.05\n",
    "vminmax = 0.5\n",
    "link_matrix = (sig_links['PCMCI'] > min_sig)\n",
    "tp.plot_graph(val_matrix=ave_val_matrices['PCMCI'],\n",
    "              link_matrix=link_matrix, \n",
    "              link_width=sig_links['PCMCI'],\n",
    "             arrow_linewidth=70.,\n",
    "              vmin_edges=-vminmax,\n",
    "              vmax_edges=vminmax,\n",
    "              var_names = var_names,\n",
    "\n",
    ")\n",
    "link_matrix = (sig_links['GC'] > min_sig)\n",
    "tp.plot_graph(val_matrix=ave_val_matrices['GC'],\n",
    "              link_matrix=link_matrix, \n",
    "              link_width=sig_links['GC'], \n",
    "              link_colorbar_label='GC',\n",
    "              node_colorbar_label='auto-GC',\n",
    "             arrow_linewidth=70.,\n",
    "              vmin_edges=-vminmax,\n",
    "              vmax_edges=vminmax,\n",
    "             var_names = var_names,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here only adding 5 independent variables makes it already impossible to detect the true links with GC, while PCMCI still detects them with almost the same power as before while still well controlling false positives at the expected 5% level (note that only 100 realizations were used to estimate the false positive rates making them not very reliable while the true positive rates are more reliable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_links = numpy.zeros((N, N, tau_max+1))\n",
    "for var in links_coeffs.keys():\n",
    "    for par in links_coeffs[var]:\n",
    "        true_links[par[0][0], var, abs(par[0][1])] = True\n",
    "# print true_links\n",
    "print \"Mean true  positives PCMCI \", numpy.mean(sig_links['PCMCI'][:,:,1:]\n",
    "                                                [true_links[:,:,1:]==True]).round(3)\n",
    "print \"Mean false positives PCMCI \", numpy.mean(sig_links['PCMCI'][:,:,1:]\n",
    "                                                [true_links[:,:,1:]==False]).round(3)\n",
    "print \"Mean true  positives GC    \", numpy.mean(sig_links['GC'][:,:,1:]\n",
    "                                                [true_links[:,:,1:]==True]).round(3)\n",
    "print \"Mean false positives GC    \", numpy.mean(sig_links['GC'][:,:,1:]\n",
    "                                                [true_links[:,:,1:]==False]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Causal effects and mediation\n",
    "\n",
    "The preceding sections were concerned with estimating causal links. In this section we discuss how the estimated time series graph can be used to evaluate causal effects and causal mediation in a linear framework as discussed in more detail in Runge et al, Nature Communications 2015. Consider the following model of a simple causal chain:\n",
    "\n",
    "\\begin{align*}\n",
    "              X_t &= \\eta^X_t \\\\\n",
    "              Y_t &= 0.5 X_{t-1} +  \\eta^Y_t \\\\\n",
    "              Z_t &= 0.5 Y_{t-1} +  \\eta^Z_t\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)\n",
    "# links_coeffs = {0: [],\n",
    "#                 1: [((0, -1), 0.5)],\n",
    "#                 2: [((1, -1), 0.5)],\n",
    "#                 }\n",
    "links_coeffs = {0: [((0,-1), 0.8)],\n",
    "                1: [((1,-1), 0.8), ((0, -1), 0.5)],\n",
    "                2: [((2,-1), 0.8), ((1, -1), 0.5)],\n",
    "                }\n",
    "var_names = [r\"$X$\", r\"$Y$\", r\"$Z$\"]\n",
    "    \n",
    "data, true_parents = pp.var_process(links_coeffs, T=1000)\n",
    "dataframe = pp.DataFrame(data)\n",
    "med = LinearMediation(dataframe=dataframe)\n",
    "med.fit_model(all_parents=true_parents, tau_max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the linear mediation model based on the true parents here, in practice these are estimated with PCMCI. If the assumption of a linear model is justified *and* causal sufficiency is fulfilled, the *link coefficient* of $X_{t-\\tau}\\to Y_t$ estimated from standardized time series (default in ``LinearMediation`` class) corresponds to the change in the expected value of $Y_t$ (in units of its standard deviation) caused by a perturbation of one standard deviation in $X_{t-\\tau}$. Let's check the link coefficient of $X_{t-2}\\to Z_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Link coefficient (0, -2) --> 2: \", med.get_coeff(i=0, tau=-2, j=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link coefficient is non-zero only for direct links. The *causal effect* evaluates also *indirect* effects and is now simply computed by summing over the products of link coefficients along all possible paths between the two variables. For example, here the causal effect of $X_{t-2}\\to Z_t$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Causal effect (0, -2) --> 2: \", med.get_ce(i=0, tau=-2, j=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *mediated causal effect* quantifies the contribution of an intermediate variable to the causal effect. For example, let's look at the contribution of $Y$ on the causal effect of $X_{t-2}\\to Z_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Mediated Causal effect (0, -2) --> 2 through 1: \", med.get_mce(i=0, tau=-2, j=2, k=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $Y$ mediates *all* of the causal effect, MCE is the same as CE here. Mediation analysis is a powerful tool to quantify not only direct causal links, but also indirect pathways. This can answer questions such as \"How important is one process for the causal mechanism between two others?\". In the ``tigramite.plotting`` module are functions to visualize causal pathways both in the aggregated network and in the time series graph. Here we look at all causal pathways between $X_{t-4}$ and $Z_t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0; tau=4; j=2\n",
    "graph_data = med._get_mediation_graph_data(i=i, tau=tau, j=j)\n",
    "tp.plot_mediation_time_series_graph(\n",
    "    var_names=var_names,\n",
    "    path_node_array=graph_data['path_node_array'],\n",
    "    tsg_path_val_matrix=graph_data['tsg_path_val_matrix']\n",
    "    )\n",
    "tp.plot_mediation_graph(\n",
    "                    var_names=var_names,\n",
    "                    path_val_matrix=graph_data['path_val_matrix'], \n",
    "                    path_node_array=graph_data['path_node_array'],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both plots, the node color depicts the mediation of a variable and the link colors depict the link coefficients. The graph plot in the bottom panel is easier to visualize for more complex pathways, but it's harder to see the pathways across variables *and* in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal effect and mediation analysis can also be used for more aggregate measures. The Average Causal Effect (ACE) quantifies how strong the effect of a single variable on the whole system is and the Average Causal Susceptibility (ACS) quantifies how strong a single variable is effected by perturbations entering elsewhere in the system. Last, the Average Mediated Causal Effect (AMCE) quantifies how much a single variable mediates causal effects between any two other processes. In Runge et al, Nature Communications (2015), these measures are compared with conventional complex network measures to show that causal effect measures are better interpretable alternatives. For example, *betweenness centrality* gives the average number of shortest paths going through a particular node. However, causal effects do not necessarily take shortest paths and betweenness also does not properly take into account the causal effect weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Average Causal Effect X=%.2f, Y=%.2f, Z=%.2f \" % tuple(med.get_all_ace())\n",
    "print \"Average Causal Susceptibility X=%.2f, Y=%.2f, Z=%.2f \" % tuple(med.get_all_acs())\n",
    "print \"Average Mediated Causal Effect X=%.2f, Y=%.2f, Z=%.2f \" % tuple(med.get_all_amce())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that per default self-loops are excluded in these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Prediction\n",
    "\n",
    "The ``tigramite.model`` file also contains a class to perform predictions based on the sklearn models. The ``Prediction`` class includes a wrapper around ``run_pc_stable`` form the ``PCMCI`` class to perform predictor selection. Consider the following data generation process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(42)\n",
    "T = 200\n",
    "links_coeffs = {0: [((0, -1), 0.6)],\n",
    "                1: [((1, -1), 0.6), ((0, -1), 0.8)],\n",
    "                2: [((2, -1), 0.5), ((1, -1), 0.7)],  # ((0, -1), c)],\n",
    "                }\n",
    "data, true_parents = pp.var_process(links_coeffs, T=T)\n",
    "dataframe = pp.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the ``Prediction`` class with ``cond_ind_model=ParCorr``. Optional test parameters can be passed on by ``cond_ind_params``. Secondly, we choose ``sklearn.linear_model.LinearRegression`` here for prediction. Also here, parameters can be passed on via ``prediction_model_params``. Last, we scale the data via ``data_transform``. The class takes care of rescaling the data for prediction. The parameters ``train_indices`` and ``test_indices`` are used to divide the data up into a training set and test set. The training set is used to select predictors and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Initialize conditional independence test\n",
      "\n",
      "Parameters:\n",
      "independence test = par_corr\n",
      "significance = analytic\n",
      "use_mask = True\n",
      "mask_type = y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = Prediction(dataframe=dataframe,\n",
    "        cond_ind_model=ParCorr,   #CMIknn ParCorr\n",
    "#         cond_ind_params = {'knn':0.1, 'significance':'fixed_thres', 'fixed_thres':0.01},\n",
    "        prediction_model = sklearn.linear_model.LinearRegression,\n",
    "#         prediction_model = sklearn.gaussian_process.GaussianProcessRegressor,\n",
    "        # prediction_model = sklearn.neighbors.KNeighborsRegressor,\n",
    "    # prediction_model_params={'fit_intercept':False},\n",
    "    # prediction_model_params = {'n_neighbors':5},\n",
    "#     prediction_model_params = {'alpha':0., 'kernel':sklearn.gaussian_process.kernels.RBF() +\n",
    "#                                         sklearn.gaussian_process.kernels.WhiteKernel()},\n",
    "    data_transform=sklearn.preprocessing.StandardScaler(),\n",
    "    train_indices= range(int(0.8*T)),\n",
    "    test_indices= range(int(0.8*T), T),\n",
    "    verbosity=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we select a superset of causal predictors up to a maximum past lag of ``tau_max`` using ``get_predictors`` for the target variable 2 at a prediction horizon of ``steps_ahead``. We use ``pc_alpha=None`` which optimizes the parameter based on the Akaike score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Running Tigramite PC algorithm\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "selected_variables = [2]\n",
      "independence test = par_corr\n",
      "tau_min = 2\n",
      "tau_max = 30\n",
      "pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "max_conds_dim = None\n",
      "max_combinations = 1\n",
      "\n",
      "\n",
      "\n",
      "## Variable 2\n",
      "\n",
      "## Resulting condition sets:\n",
      "\n",
      "    Variable 0 has 0 parent(s):\n",
      "\n",
      "    Variable 1 has 0 parent(s):\n",
      "\n",
      "    Variable 2 has 4 parent(s):\n",
      "    [pc_alpha = 0.2]\n",
      "        (1 -2): max_pval = 0.00000, min_val = 0.641\n",
      "        (0 -2): max_pval = 0.00057, min_val = 0.340\n",
      "        (2 -18): max_pval = 0.02001, min_val = 0.234\n",
      "        (1 -3): max_pval = 0.17335, min_val = 0.140\n"
     ]
    }
   ],
   "source": [
    "tau_max = 30\n",
    "steps_ahead = 2\n",
    "target = 2\n",
    "\n",
    "all_predictors = pred.get_predictors(\n",
    "                  selected_targets=[target],\n",
    "                  steps_ahead=steps_ahead,\n",
    "                  tau_max=tau_max,\n",
    "                  pc_alpha=None\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictors now efficiently avoid overfitting in the following model fit. Here one can specify whether multiple target variables should be fit at once (assuming that for all of these predictors have been estimated beforehand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.fit(target_predictors=all_predictors, \n",
    "                selected_targets=[target],\n",
    "                    tau_max=tau_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to predict the target variable at the test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Predicting target 2\n",
      "##\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f8f7f7fa210>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngoiIAEoIIiISpoQgIiKAEoKIiIT9f//Hj7fUqVu7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f845edb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = pred.predict(target)\n",
    "true_data = pred.get_test_array()[0]\n",
    "\n",
    "plt.scatter(true_data, predicted)\n",
    "plt.title(r\"NRMSE = %.2f\" % (numpy.abs(true_data - predicted).mean()/true_data.std()))\n",
    "plt.plot(true_data, true_data, 'k-')\n",
    "plt.xlabel('True test data')\n",
    "plt.ylabel('Predicted test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction is much better than using *all* past variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Predicting target 2\n",
      "##\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f8f7f720fd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f7f8ae1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole_predictors = {2:[(i, -tau) for i in range(3) for tau in range(1, tau_max+1)]}\n",
    "pred.fit(target_predictors=whole_predictors, \n",
    "                selected_targets=[target],\n",
    "                    tau_max=tau_max)\n",
    "\n",
    "predicted = pred.predict(target)\n",
    "true_data = pred.get_test_array()[0]\n",
    "\n",
    "plt.scatter(true_data, predicted)\n",
    "plt.plot(true_data, true_data, 'k-')\n",
    "plt.title(r\"NRMSE = %.2f\" % (numpy.abs(true_data - predicted).mean()/true_data.std()))\n",
    "plt.xlabel('True test data')\n",
    "plt.ylabel('Predicted test data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
