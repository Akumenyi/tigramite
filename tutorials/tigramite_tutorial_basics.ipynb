{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal discovery with `TIGRAMITE`\n",
    "\n",
    "TIGRAMITE is a time series analysis python module. It allows to reconstruct graphical models (conditional independence graphs) from discrete or continuously-valued time series based on the PCMCI method and create high-quality plots of the results.\n",
    "This tutorial explains the main features in walk-through examples. It covers:\n",
    "\n",
    "1. Basic usage\n",
    "2. Plotting\n",
    "3. Nonlinear conditional independence tests\n",
    "4. Symbolic time series\n",
    "\n",
    "PCMCI is described here: J. Runge et al. (2018): Detecting Causal Associations in Large Nonlinear Time Series Datasets. https://arxiv.org/abs/1702.07007v2\n",
    "\n",
    "See the following paper for theoretical background:\n",
    "Runge, Jakob. 2018. “Causal Network Reconstruction from Time Series: From Theoretical Assumptions to Practical Estimation.” Chaos: An Interdisciplinary Journal of Nonlinear Science 28 (7): 075310."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline     \n",
    "## use `%matplotlib notebook` for interactive figures\n",
    "# plt.style.use('ggplot')\n",
    "import sklearn\n",
    "\n",
    "import tigramite\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, GPDC, CMIknn, CMIsymb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider time series coming from a data generating process\n",
    "\n",
    "\\begin{align*}\n",
    "X^0_t &= 0.7 X^0_{t-1} - 0.8 X^1_{t-1} + \\eta^0_t\\\\\n",
    "X^1_t &= 0.8 X^1_{t-1} + 0.8 X^3_{t-1} + \\eta^1_t\\\\\n",
    "X^2_t &= 0.5 X^2_{t-1} + 0.5 X^1_{t-2} + 0.6 X^3_{t-3} + \\eta^2_t\\\\\n",
    "X^3_t &= 0.7 X^3_{t-1} + \\eta^3_t\\\\\n",
    "\\end{align*}\n",
    "\n",
    "where $\\eta$ are independent zero-mean unit variance random variables. Our goal is to reconstruct the drivers of each variable. In Tigramite such a process can be generated with the function ``pp.var_process``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)     # Fix random seed\n",
    "links_coeffs = {0: [((0, -1), 0.7), ((1, -1), -0.8)],\n",
    "                1: [((1, -1), 0.8), ((3, -1), 0.8)],\n",
    "                2: [((2, -1), 0.5), ((1, -2), 0.5), ((3, -3), 0.6)],\n",
    "                3: [((3, -1), 0.4)],\n",
    "                }\n",
    "T = 1000     # time series length\n",
    "data, true_parents_neighbors = pp.var_process(links_coeffs, T=T)\n",
    "T, N = data.shape\n",
    "\n",
    "# Initialize dataframe object\n",
    "dataframe = pp.DataFrame(data)\n",
    "\n",
    "# Specify time axis and variable names\n",
    "datatime = np.arange(len(data))\n",
    "var_names = [r'$X^0$', r'$X^1$', r'$X^2$', r'$X^3$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we plot the time series. This can be done with the function ``tp.plot_timeseries``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp.plot_timeseries(data, datatime, var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's stationary and doesn't contain missing values (covered in other tutorial). Next, we choose a conditional independence test, here we start with ``ParCorr`` implementing linear partial correlation. With ``significance='analytic'`` the null distribution is assumed to be Student's $t$. Then we initialize the ``PCMCI`` method with  ``dataframe``, ``cond_ind_test``, and (optionally) ``var_names``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr(significance='analytic')\n",
    "pcmci = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the causal algorithm, it's a good idea to plot the lagged unconditional dependencies, e.g., the lagged correlations. This can help to identify which maximal time lag ``tau_max`` to choose in the causal algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = pcmci.get_lagged_dependencies(tau_max=20)\n",
    "lag_func_matrix = tp.plot_lagfuncs(val_matrix=correlations, setup_args={'var_names':var_names, \n",
    "                                    'x_base':5, 'y_base':.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dependencies decay beyond a maximum lag of around 8, we choose ``tau_max=8`` for PCMCI. The other main parameter is ``pc_alpha`` which sets the significance level in the condition-selection step. Here we let PCMCI choose the optimal value by setting it to ``pc_alpha=None``. Then PCMCI will optimize this parameter in the ParCorr case by the Akaike Information criterion among a reasonable default list of values (e.g., ``pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci.verbosity = 1\n",
    "results = pcmci.run_pcmci(tau_max=8, pc_alpha=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output, PCMCI selected different ``pc_alpha`` for each variable. The result of ``run_pcmci`` is a dictionary containing the matrix of p-values, the matrix of test statistic values (here MCI partial correlations), and optionally its confidence bounds (can be specified upon initializing ``ParCorr``). ``p_matrix`` and ``val_matrix`` are of shape ``(N, N, tau_max+1)`` with entry ``(i, j, \\tau)`` denoting the test for the link $X^i_{t-\\tau} \\to X^j_t$. Per default, the MCI values for $\\tau=0$ are not evaluated (can be changed with ``tau_min`` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p-values\")\n",
    "print (results['p_matrix'].round(3))\n",
    "print(\"MCI partial correlations\")\n",
    "print (results['val_matrix'].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to control for the $N^2 \\tau_\\max$ tests conducted here, we can further correct the p-values, e.g., by False Discovery Rate (FDR) control yielding the ``q_matrix``. At a chosen significance level the detected parents of each variable can then be printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], fdr_method='fdr_bh')\n",
    "pcmci.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        q_matrix = q_matrix,\n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tigramite currently offers three plotting options: The lag function matrix (as shown above), the time series graph, and the process graph which aggregates the information in the time series graph. Both take as arguments the boolean ``link_matrix`` which denotes significant links by ``1``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_matrix = pcmci.return_significant_parents(pq_matrix=q_matrix,\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process graph, the node color denotes the auto-MCI value and the link colors the cross-MCI value. If links occur at multiple lags between two variables, the link color denotes the strongest one and the label lists all significant lags in order of their strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp.plot_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='cross-MCI',\n",
    "    node_colorbar_label='auto-MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series graph\n",
    "tp.plot_time_series_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the process graph is nicer to look at, the time series graph better represents the spatio-temporal dependency structure from which causal pathways can be read off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nonlinear conditional independence tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If nonlinear dependencies are present, it is advisable to use a nonparametric test. Consider the following model:\n",
    "\n",
    "\\begin{align*}\n",
    "    X^0_t &= 0.2 (X^1_{t-1})^2 + \\eta^0_t\\\\\n",
    "    X^1_t &= \\eta^1_t \\\\\n",
    "    X^2_t &= 0.3 (X^1_{t-2})^2 + \\eta^2_t\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "data = np.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "    data[t, 0] += 0.4*data[t-1, 1]**2\n",
    "    data[t, 2] += 0.3*data[t-2, 1]**2\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci_parcorr = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_parcorr.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_parcorr.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``ParCorr`` here fails in two ways: (1) It cannot detect the two nonlinear links, (2) it wrongly detects a link $X^0_{t-1} \\to X^2_t$ because it also cannot *condition out* a nonlinear dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPDC\n",
    "\n",
    "Tigramite covers nonlinear additive dependencies with a test based on *Gaussian process* regression and a *distance correlation* (``GPDC``) on the residuals. For GPDC no analytical null distribution is available. One can either use a computationally expensive shuffle test throughout or the null distribution can be pre-computed for different anticipated sample sizes with ``generate_and_save_nulldists`` and stored to disk (could be run overnight:). Then ``significance='analytic'`` loads this file. If no file is given, the distribution is generated and stored in cache. GP regression is performed with ``sklearn`` default parameters, except for the *kernel* which here defaults to the radial basis function + a white kernel (both hyperparameters are internally optimized) and the assumed noise level ``alpha`` which is set to zero since we added a white kernel. These and other parameters can be set via the ``gp_params`` dictionary. See the documentation in ``sklearn`` for further discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpdc = GPDC(significance='analytic', gp_params=None)\n",
    "# gpdc.generate_and_save_nulldists(sample_sizes=range(495, 501),\n",
    "#     null_dist_filename='dc_nulldists.npz')\n",
    "gpdc.null_dist_filename ='dc_nulldists.npz'\n",
    "pcmci_gpdc = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=gpdc,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to ParCorr, the nonlinear links are correctly detected with GPDC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pcmci_gpdc.run_pcmci(tau_max=2, pc_alpha=0.1)\n",
    "pcmci_gpdc.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a short excursion, we can see how GPDC works looking at the scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array, dymmy, dummy = gpdc._get_array(X=[(0, -1)], Y=[(2, 0)], Z=[(1, -2)], tau_max=2)\n",
    "x, meanx = gpdc._get_single_residuals(array, target_var=0, return_means=True)\n",
    "y, meany = gpdc._get_single_residuals(array, target_var=1, return_means=True)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8,3))\n",
    "axes[0].scatter(array[2], array[0], color='grey')\n",
    "axes[0].scatter(array[2], meanx, color='black')\n",
    "axes[0].set_title(\"GP of %s on %s\" % (var_names[0], var_names[1]) )\n",
    "axes[0].set_xlabel(var_names[1]); axes[0].set_ylabel(var_names[0])\n",
    "axes[1].scatter(array[2], array[1], color='grey')\n",
    "axes[1].scatter(array[2], meany, color='black')\n",
    "axes[1].set_title(\"GP of %s on %s\" % (var_names[2], var_names[1]) )\n",
    "axes[1].set_xlabel(var_names[1]); axes[1].set_ylabel(var_names[2])\n",
    "axes[2].scatter(x, y, color='red')\n",
    "axes[2].set_title(\"DC of residuals:\" \"\\n val=%.3f / p-val=%.3f\" % (gpdc.run_test(\n",
    "            X=[(0, -1)], Y=[(2, 0)], Z=[(1, -2)], tau_max=2)) )\n",
    "axes[2].set_xlabel(\"resid. \"+var_names[0]); axes[2].set_ylabel(\"resid. \"+var_names[2])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some even more nonlinear dependencies in a model with multiplicative noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = np.random.randn(500, 3)\n",
    "for t in range(1, 500):\n",
    "    data[t, 0] *= 0.2*data[t-1, 1]\n",
    "    data[t, 2] *= 0.3*data[t-2, 1]\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since multiplicative noise violates the assumption of additive dependencies underlying GPDC, the spurious link  $X^0_{t-1} \\to X^2_t$ is wrongly detected because it cannot be *conditioned out*. In contrast to ParCorr, however, the two true links *are* detected because DC detects any kind of dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci_gpdc = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=gpdc,\n",
    "    var_names=var_names)\n",
    "results = pcmci_gpdc.run_pcmci(tau_max=2, pc_alpha=0.1)\n",
    "pcmci_gpdc.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see in the scatter plot, that the Gaussian Process cannot fit the dependencies and the residuals are, thus, not independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array, dymmy, dummy = gpdc._get_array(X=[(0, -1)], Y=[(2, 0)], Z=[(1, -2)], tau_max=2)\n",
    "x, meanx = gpdc._get_single_residuals(array, target_var=0, return_means=True)\n",
    "y, meany = gpdc._get_single_residuals(array, target_var=1, return_means=True)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8,3))\n",
    "axes[0].scatter(array[2], array[0], color='grey')\n",
    "axes[0].scatter(array[2], meanx, color='black')\n",
    "axes[0].set_title(\"GP of %s on %s\" % (var_names[0], var_names[1]) )\n",
    "axes[0].set_xlabel(var_names[1]); axes[0].set_ylabel(var_names[0])\n",
    "axes[1].scatter(array[2], array[1], color='grey')\n",
    "axes[1].scatter(array[2], meany, color='black')\n",
    "axes[1].set_title(\"GP of %s on %s\" % (var_names[2], var_names[1]) )\n",
    "axes[1].set_xlabel(var_names[1]); axes[1].set_ylabel(var_names[2])\n",
    "axes[2].scatter(x, y, color='red', alpha=0.3)\n",
    "axes[2].set_title(\"DC of residuals:\" \"\\n val=%.3f / p-val=%.3f\" % (gpdc.run_test(\n",
    "            X=[(0, -1)], Y=[(2, 0)], Z=[(1, -2)], tau_max=2)) )\n",
    "axes[2].set_xlabel(\"resid. \"+var_names[0]); axes[2].set_ylabel(\"resid. \"+var_names[2])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMIknn\n",
    "\n",
    "The most general conditional independence test implemented in Tigramite is CMIknn based on conditional mutual information estimated with a k-nearest neighbor estimator. This test is described in the paper \n",
    "\n",
    "Runge, Jakob. 2018. “Conditional Independence Testing Based on a Nearest-Neighbor Estimator of Conditional Mutual Information.” In Proceedings of the 21st International Conference on Artificial Intelligence and Statistics. \n",
    "\n",
    "CMIknn involves no assumptions about the dependencies. The parameter ``knn`` determines the size of hypercubes, ie., the (data-adaptive) local length-scale. Now we cannot even pre-compute the null distribution because CMIknn is not residual-based like GPDC and the nulldistribution depends on many more factors. We, therefore, use ``significance='shuffle_test'`` to generate it in each individual test. The shuffle test for testing $I(X;Y|Z)=0$ shuffles $X$ values *locally*: Each sample point $i$’s $x$-value is mapped randomly\n",
    "to one of its nearest neigbors (``shuffle_neighbors`` parameter) in subspace $Z$. The following cell may take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi_knn = CMIknn(significance='shuffle_test', knn=0.1, shuffle_neighbors=5)\n",
    "pcmci_cmi_knn = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=cmi_knn,\n",
    "    var_names=var_names,\n",
    "    verbosity=2)\n",
    "results = pcmci_cmi_knn.run_pcmci(tau_max=2, pc_alpha=0.05)\n",
    "pcmci_cmi_knn.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Significant links at alpha = 0.01:\n",
    "\n",
    "#     Variable $X^0$ has 1 link(s):\n",
    "#         ($X^1$ -1): pval = 0.00000 | val = 0.108\n",
    "\n",
    "#     Variable $X^1$ has 0 link(s):\n",
    "\n",
    "#     Variable $X^2$ has 1 link(s):\n",
    "#         ($X^1$ -2): pval = 0.00000 | val = 0.080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_matrix = pcmci_cmi_knn.return_significant_parents(pq_matrix=results['p_matrix'],\n",
    "                        val_matrix=results['val_matrix'], alpha_level=0.01)['link_matrix']\n",
    "tp.plot_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    link_matrix=link_matrix,\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='cross-MCI',\n",
    "    node_colorbar_label='auto-MCI',\n",
    "    vmin_edges=0.,\n",
    "    vmax_edges = 0.3,\n",
    "    edge_ticks=0.05,\n",
    "    cmap_edges='OrRd',\n",
    "    vmin_nodes=0,\n",
    "    vmax_nodes=.5,\n",
    "    node_ticks=.1,\n",
    "    cmap_nodes='OrRd',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here CMIknn correctly detects the true links and also unveils the spurious link. While CMIknn may now seem as the best independence test choice, we have to note that the generality comes at the cost of much lower power for the case that the dependencies actually follow some parametric form. Then ParCorr or GPDC are much more powerful measures. Of course, ParCorr also detects linear links better than GPDC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCOT\n",
    "\n",
    "Another option as a fully non-parametric test is based on Kernel measures (https://arxiv.org/abs/1702.03877). We here implement a test wrapped around the r-package ``rcit``, so you need to set that up as described in the documentation of the RCOT class. Tigramite provides a bash script ``install_r_packages.sh`` that will install RCOT (this might not work in Python3.6, just Python2.7). The test does not require a shuffle test and is, hence, much faster than CMIknn. However, it should only be used for sample sizes larger than 1000 or so, because the analytical approximation of the null distribution may not be valid for smaller sizes, see the results in the AISTATS paper referenced above. Another drawback vs CMIknn is that it may not work for nonlinearities on very fine scales. The method is very new and extended numerical comparisons are still missing. The interpretation of the RCOT value is not straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tigramite.independence_tests import RCOT\n",
    "rcot = RCOT(significance='analytic')\n",
    "pcmci_rcot = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=rcot,\n",
    "    var_names=var_names,\n",
    "    verbosity=0)\n",
    "results = pcmci_rcot.run_pcmci(tau_max=2, pc_alpha=0.05)\n",
    "pcmci_rcot.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Symbolic time series\n",
    "\n",
    "Symbolic (or discrete) data may arise naturally or continuously-valued time series can be converted to symbolic data. To accommodate such time series, Tigramite includes the ``CMIsymb`` conditional independence test based on conditional mutual information estimated directly from the histogram of discrete values. Usually a (quantile-)binning  applied to continuous data in order to use a discrete CMI estimator is not recommended (rather use ``CMIknn``), but here we do it anyway to get some symbolic data. We again consider the nonlinear time series example and convert to a symbolic series with 4 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "data = np.random.randn(2000, 3)\n",
    "for t in range(1, 2000):\n",
    "    data[t, 0] += 0.4*data[t-1, 1]**2\n",
    "    data[t, 2] += 0.3*data[t-2, 1]**2\n",
    "data = pp.quantile_bin_array(data, bins=4)\n",
    "dataframe = pp.DataFrame(data)\n",
    "tp.plot_timeseries(data, figsize=(10,4), var_names=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMIsymb is initialized with ``n_symbs=None`` implying that the number of symbols is determined as ``n_symbs=data.max()+1``. Again, we have to use a shuffle test. Symbolic CMI works not very well here, only for 2000 samples was the correct graph reliably detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi_symb = CMIsymb(significance='shuffle_test', n_symbs=None)\n",
    "pcmci_cmi_symb = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=cmi_symb,\n",
    "    var_names=var_names)\n",
    "results = pcmci_cmi_symb.run_pcmci(tau_max=2, pc_alpha=0.2)\n",
    "pcmci_cmi_symb.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Significant parents at alpha = 0.01:\n",
    "\n",
    "#     Variable $X^0$ has 1 parent(s):\n",
    "#         ($X^1$ -1): pval = 0.00000 | val = 0.040\n",
    "\n",
    "#     Variable $X^1$ has 0 parent(s):\n",
    "\n",
    "#     Variable $X^2$ has 1 parent(s):\n",
    "#         ($X^1$ -2): pval = 0.00000 | val = 0.036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
